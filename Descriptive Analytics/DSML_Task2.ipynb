{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "\n",
    "import geopandas as gpd\n",
    "import geopy as gp\n",
    "from geopy import distance\n",
    "import geoplot as geoplot\n",
    "import mapclassify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cologneData = pd.read_csv(\"../../Data sets/koeln.csv\")\n",
    "\n",
    "essenData = pd.read_csv(\"../../Data sets/essen.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Weekdays from day Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weekday_match (ts):\n",
    "    return ts.weekday()\n",
    "\n",
    "def hour_match (ts):\n",
    "    return ts.hour\n",
    "\n",
    "def createDatetime (ts):\n",
    "    return datetime.strptime(str(ts), '%Y-%m-%d').date()\n",
    "\n",
    "def createTime (ts):\n",
    "    return datetime.strptime(ts, '%H:%M:%S').time()\n",
    "\n",
    "def timestampNormalize (ts):\n",
    "    return ts.replace(minute=0, second=0)\n",
    "# creates a timestamp that is comparable to weather data\n",
    "def timestamp_create(stamp):\n",
    "    newStamp =  datetime.strptime(stamp, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    newStamp = newStamp.replace(minute=0, second=0)\n",
    "    \n",
    "    return newStamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate day and time strings as preparation for timestamp creation\n",
    "essenData[\"Zeitstempel\"] = essenData[\"day\"] + ' ' + essenData[\"time\"]\n",
    "cologneData[\"Zeitstempel\"] = cologneData[\"day\"] + ' ' + cologneData[\"time\"]\n",
    "# create timestamp for comparison of bike rental data and weather data\n",
    "essenData[\"Zeitstempel\"] = essenData[\"Zeitstempel\"].map(timestamp_create)\n",
    "cologneData[\"Zeitstempel\"] = cologneData[\"Zeitstempel\"].map(timestamp_create)\n",
    "# change datatypes to make them more comparable and accessable\n",
    "essenData[\"day\"] = essenData[\"day\"].map(createDatetime)\n",
    "\n",
    "essenData[\"time\"] = essenData[\"time\"].map(createTime)\n",
    "\n",
    "cologneData[\"day\"] = cologneData[\"day\"].map(createDatetime)\n",
    "\n",
    "cologneData[\"time\"] = cologneData[\"time\"].map(createTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add weekday and hour feauture\n",
    "essenData[\"weekday\"]=essenData[\"day\"].map(weekday_match)\n",
    "essenData[\"hour\"] = essenData[\"time\"].map(hour_match)\n",
    "\n",
    "cologneData[\"weekday\"]=cologneData[\"day\"].map(weekday_match)\n",
    "cologneData[\"hour\"] = cologneData[\"time\"].map(hour_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform value to day string\n",
    "def getDayFromWeekdayNumber(argument):\n",
    "    switcher = {\n",
    "        0: \"Monday\",\n",
    "        1: \"Tuesday\",\n",
    "        2: \"Wednesday\",\n",
    "        3: \"Thursday\",\n",
    "        4: \"Friday\",\n",
    "        5: \"Saturday\",\n",
    "        6: \"Sunday\",\n",
    "    }\n",
    "    return switcher.get(argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change weekday value to string of suitable day\n",
    "essenData[\"weekday2\"] = essenData[\"weekday\"].map(getDayFromWeekdayNumber)\n",
    "\n",
    "cologneData[\"weekday2\"] = cologneData[\"weekday\"].map(getDayFromWeekdayNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning data with the right lat. and lng.\n",
    "cologneCleanedData = cologneData\n",
    "cologneCleanedData = cologneCleanedData[cologneCleanedData['orig_lat'] >= 50]\n",
    "cologneCleanedData = cologneCleanedData[ cologneCleanedData['orig_lat'] < 52]\n",
    "cologneCleanedData = cologneCleanedData[cologneCleanedData['orig_lng'] >= 6]\n",
    "cologneCleanedData = cologneCleanedData[ cologneCleanedData['orig_lng'] < 8]\n",
    "\n",
    "essenCleanedData = essenData\n",
    "essenCleanedData = essenCleanedData[essenCleanedData['orig_lat'] >= 50]\n",
    "essenCleanedData = essenCleanedData[ essenCleanedData['orig_lat'] < 52]\n",
    "essenCleanedData = essenCleanedData[essenCleanedData['orig_lng'] >= 6]\n",
    "essenCleanedData = essenCleanedData[ essenCleanedData['orig_lng'] < 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_match (ts):\n",
    "    return datetime.strptime(str(ts), '%Y%m%d%H%M')\n",
    "\n",
    "def ts_match2 (ts):\n",
    "    return datetime.strptime(str(ts), '%Y%m%d')\n",
    "\n",
    "def getTime (ts):\n",
    "    return ts.time()\n",
    "\n",
    "def getDay (ts):\n",
    "    return ts.date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Air Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Data\n",
    "airPressure = pd.read_csv(\"../weather_data/3_weather_data/air_pressure/data_air_pressure_hpa_hourly.csv\")\n",
    "\n",
    "# change timestamp format\n",
    "\n",
    "airPressure[\"Zeitstempel\"] = airPressure[\"Zeitstempel\"].map(ts_match)\n",
    "# airPressure[\"time\"] = airPressure[\"Zeitstempel\"].map(getTime)\n",
    "# airPressure[\"day\"] = airPressure[\"Zeitstempel\"].map(getDay)\n",
    "\n",
    "# delete Zeitstempel column (optional) \n",
    "airPressure = airPressure.drop(columns=[\"Produkt_Code\", \"Qualitaet_Niveau\", \"Qualitaet_Byte\"])\n",
    "\n",
    "airPressureColBo = airPressure.loc[airPressure.SDO_ID == 2667]\n",
    "airPressureEss= airPressure.loc[airPressure.SDO_ID == 1303]\n",
    "\n",
    "# rearrange column order\n",
    "cols = airPressure.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "\n",
    "airPressure = airPressure[cols] \n",
    "\n",
    "# # show Dataframe\n",
    "# #airPressure.info()\n",
    "airPressureColBo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Air Temparature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "airTemperature = pd.read_csv(\"../weather_data/3_weather_data/air_temperature/data_Temperature_air_2m_hourly.csv\")\n",
    "\n",
    "# change timestamp format\n",
    "airTemperature[\"Zeitstempel\"] = airTemperature[\"Zeitstempel\"].map(ts_match)\n",
    "# airTemperature[\"time\"] = airTemperature[\"Zeitstempel\"].map(getTime)\n",
    "# airTemperature[\"day\"] = airTemperature[\"Zeitstempel\"].map(getDay)\n",
    "    \n",
    "# delete Zeitstempel column (optional) \n",
    "airTemperature = airTemperature.drop(columns=[\"Produkt_Code\", \"Qualitaet_Niveau\", \"Qualitaet_Byte\"])\n",
    "\n",
    "# airTemperatureCol = airTemperature.loc[airTemperature.SDO_ID == 2968]\n",
    "airTemperatureColBo = airTemperature.loc[airTemperature.SDO_ID == 2667]\n",
    "airTemperatureEss= airTemperature.loc[airTemperature.SDO_ID == 1303]\n",
    "\n",
    "# print(len(airTemperatureCol))\n",
    "print(len(airTemperatureColBo))\n",
    "print(len(airTemperatureEss))\n",
    "\n",
    "# show Dataframe\n",
    "airTemperatureColBo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "cloudCoverage = pd.read_csv(\"../weather_data/3_weather_data/cloud_coverage/data_Hourly_observ_cloud_coverage.csv\")\n",
    "\n",
    "# change timestamp format\n",
    "cloudCoverage[\"Zeitstempel\"] = cloudCoverage[\"Zeitstempel\"].map(ts_match)\n",
    "#cloudCoverage[\"time\"] = cloudCoverage[\"Zeitstempel\"].map(getTime)\n",
    "#cloudCoverage[\"day\"] = cloudCoverage[\"Zeitstempel\"].map(getDay)\n",
    "\n",
    "# delete Zeitstempel column (optional) \n",
    "cloudCoverage = cloudCoverage.drop(columns=[\"Produkt_Code\", \"Qualitaet_Niveau\", \"Qualitaet_Byte\"])\n",
    "\n",
    "cloudCoverageColBo = cloudCoverage.loc[cloudCoverage.SDO_ID == 2667]\n",
    "cloudCoverageEss= cloudCoverage.loc[cloudCoverage.SDO_ID == 1303]\n",
    "\n",
    "print(cloudCoverage[\"SDO_ID\"].unique())\n",
    "\n",
    "print(len(cloudCoverageColBo))\n",
    "print(len(cloudCoverageEss))\n",
    "\n",
    "# show Dataframe\n",
    "#cloudCoverage.info()\n",
    "cloudCoverageColBo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "precipitationForm = pd.read_csv(\"../weather_data/3_weather_data/form_of_precipitation/data_form_of_rain_precipitation.csv\")\n",
    "\n",
    "# change timestamp format\n",
    "precipitationForm[\"Zeitstempel\"] = precipitationForm[\"Zeitstempel\"].map(ts_match)\n",
    "# precipitationForm[\"time\"] = precipitationForm[\"Zeitstempel\"].map(getTime)\n",
    "# precipitationForm[\"day\"] = precipitationForm[\"Zeitstempel\"].map(getDay)\n",
    "\n",
    "# delete Zeitstempel column (optional) \n",
    "precipitationForm = precipitationForm.drop(columns=[\"Produkt_Code\", \"Qualitaet_Niveau\", \"Qualitaet_Byte\"])\n",
    "\n",
    "precipitationFormColBo = precipitationForm.loc[precipitationForm.SDO_ID == 2667]\n",
    "precipitationFormEss= precipitationForm.loc[precipitationForm.SDO_ID == 1303]\n",
    "\n",
    "print(precipitationForm[\"SDO_ID\"].unique())\n",
    "\n",
    "print(len(precipitationFormColBo))\n",
    "print(len(precipitationFormEss))\n",
    "\n",
    "# show Dataframe\n",
    "#precipitationForm.info()\n",
    "precipitationFormColBo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "precipitationAmount = pd.read_csv(\"../weather_data/3_weather_data/precipitation_amount/data_volume_rain_precipitation_hourly.csv\")\n",
    "\n",
    "# change timestamp format\n",
    "precipitationAmount[\"Zeitstempel\"] = precipitationAmount[\"Zeitstempel\"].map(ts_match)\n",
    "# precipitationAmount[\"time\"] = precipitationAmount[\"Zeitstempel\"].map(getTime)\n",
    "# precipitationAmount[\"day\"] = precipitationAmount[\"Zeitstempel\"].map(getDay)\n",
    "\n",
    "# delete Zeitstempel column (optional) \n",
    "precipitationAmount = precipitationAmount.drop(columns=[\"Produkt_Code\", \"Qualitaet_Niveau\", \"Qualitaet_Byte\"])\n",
    "\n",
    "precipitationAmountCol = precipitationAmount.loc[precipitationAmount.SDO_ID == 2968]\n",
    "precipitationAmountColBo = precipitationAmount.loc[precipitationAmount.SDO_ID == 2667]\n",
    "precipitationAmountEss= precipitationAmount.loc[precipitationAmount.SDO_ID == 1303]\n",
    "\n",
    "print(precipitationAmount[\"SDO_ID\"].unique())\n",
    "print(len(precipitationAmountCol))\n",
    "print(len(precipitationAmountColBo))\n",
    "print(len(precipitationAmountEss))\n",
    "\n",
    "# show Dataframe\n",
    "#precipitationAmount.info()\n",
    "precipitationAmountColBo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "relativeHumidity= pd.read_csv(\"../weather_data/3_weather_data/relative_humidity_percent/data_relative_humidity_hourly.csv\")\n",
    "\n",
    "# change timestamp format\n",
    "relativeHumidity[\"Zeitstempel\"] = relativeHumidity[\"Zeitstempel\"].map(ts_match)\n",
    "# relativeHumidity[\"time\"] = relativeHumidity[\"Zeitstempel\"].map(getTime)\n",
    "# relativeHumidity[\"day\"] = relativeHumidity[\"Zeitstempel\"].map(getDay)\n",
    "\n",
    "# delete Zeitstempel column (optional) \n",
    "relativeHumidity = relativeHumidity.drop(columns=[\"Produkt_Code\", \"Qualitaet_Niveau\", \"Qualitaet_Byte\"])\n",
    "\n",
    "relativeHumidityCol = relativeHumidity.loc[relativeHumidity.SDO_ID == 2968]\n",
    "relativeHumidityColBo = relativeHumidity.loc[relativeHumidity.SDO_ID == 2667]\n",
    "relativeHumidityEss= relativeHumidity.loc[relativeHumidity.SDO_ID == 1303]\n",
    "\n",
    "print(relativeHumidity[\"SDO_ID\"].unique())\n",
    "print(len(relativeHumidityCol))\n",
    "print(len(relativeHumidityColBo))\n",
    "print(len(relativeHumidityEss))\n",
    "\n",
    "# show Dataframe\n",
    "#relativeHumidity.info()\n",
    "relativeHumidityColBo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soil Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "soilTemperature = pd.read_csv(\"../weather_data/3_weather_data/soil_temperatur_depth_5cm/data_Temperature_ground_5cm_hourly.csv\")\n",
    "\n",
    "# change timestamp format\n",
    "soilTemperature[\"Zeitstempel\"] = soilTemperature[\"Zeitstempel\"].map(ts_match)\n",
    "# soilTemperature[\"time\"] = soilTemperature[\"Zeitstempel\"].map(getTime)\n",
    "# soilTemperature[\"day\"] = soilTemperature[\"Zeitstempel\"].map(getDay)\n",
    "\n",
    "# delete Zeitstempel column (optional) \n",
    "soilTemperature = soilTemperature.drop(columns=[\"Produkt_Code\", \"Qualitaet_Niveau\", \"Qualitaet_Byte\"])\n",
    "\n",
    "soilTemperatureColBo = soilTemperature.loc[soilTemperature.SDO_ID == 2667]\n",
    "soilTemperatureEss= soilTemperature.loc[soilTemperature.SDO_ID == 1303]\n",
    "\n",
    "print(soilTemperature[\"SDO_ID\"].unique())\n",
    "print(len(soilTemperatureColBo))\n",
    "print(len(soilTemperatureEss))\n",
    "\n",
    "# show Dataframe\n",
    "#soilTemperature.info()\n",
    "soilTemperatureColBo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sunshine Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "sunshineDuration = pd.read_csv(\"../weather_data/3_weather_data/sunshine_duration_hours/data_daily_observ_sunshine_duration_hours.csv\")\n",
    "\n",
    "# change timestamp format\n",
    "sunshineDuration[\"Zeitstempel\"] = sunshineDuration[\"Zeitstempel\"].map(ts_match2)\n",
    "# sunshineDuration[\"day\"] = sunshineDuration[\"Zeitstempel\"].map(getDay)\n",
    "\n",
    "# delete Zeitstempel column (optional) \n",
    "sunshineDuration = sunshineDuration.drop(columns=[\"Produkt_Code\", \"Qualitaet_Niveau\", \"Qualitaet_Byte\"])\n",
    "\n",
    "sunshineDurationColBo = sunshineDuration.loc[sunshineDuration.SDO_ID == 2667]\n",
    "sunshineDurationEss= sunshineDuration.loc[sunshineDuration.SDO_ID == 1303]\n",
    "\n",
    "print(sunshineDuration[\"SDO_ID\"].unique())\n",
    "print(len(sunshineDurationColBo))\n",
    "print(len(sunshineDurationEss))\n",
    "\n",
    "\n",
    "# show Dataframe\n",
    "#sunshineDuration.info()\n",
    "sunshineDurationColBo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "windVelocity = pd.read_csv(\"../weather_data/3_weather_data/wind_velocity/data_Wind_velocity_10m_hourly.csv\")\n",
    "\n",
    "# change timestamp format\n",
    "windVelocity[\"Zeitstempel\"] = windVelocity[\"Zeitstempel\"].map(ts_match)\n",
    "# windVelocity[\"time\"] = windVelocity[\"Zeitstempel\"].map(getTime)\n",
    "# windVelocity[\"day\"] = windVelocity[\"Zeitstempel\"].map(getDay)\n",
    "\n",
    "# delete Zeitstempel column (optional) \n",
    "windVelocity = windVelocity.drop(columns=[\"Produkt_Code\", \"Qualitaet_Niveau\", \"Qualitaet_Byte\"])\n",
    "\n",
    "windVelocityColBo = windVelocity.loc[windVelocity.SDO_ID == 2667]\n",
    "windVelocityEss= windVelocity.loc[windVelocity.SDO_ID == 1303]\n",
    "\n",
    "print(windVelocity[\"SDO_ID\"].unique())\n",
    "print(len(windVelocityColBo))\n",
    "print(len(windVelocityEss))\n",
    "\n",
    "# show Dataframe\n",
    "#windVelocity.info()\n",
    "windVelocity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the last 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Weatherdata to one Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging relevant weather datas for our correlation coefficient(Cologne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherDataColBo = airPressureColBo.merge(airTemperatureColBo, left_on=['Zeitstempel', 'SDO_ID'], right_on=['Zeitstempel', 'SDO_ID'])\n",
    "weatherDataColBo.columns = ['SDO_ID', 'Zeitstempel', 'airPressure', 'airTemperature']\n",
    "\n",
    "#merge cloudCoverage in weatherData - loss of one entrie -> Approach: Deletion - Missing Rows\n",
    "\n",
    "weatherDataColBo = weatherDataColBo.merge(cloudCoverageColBo, left_on=['Zeitstempel', 'SDO_ID'], right_on=['Zeitstempel', 'SDO_ID'])\n",
    "weatherDataColBo.columns = ['SDO_ID', 'Zeitstempel', 'airPressure', 'airTemperature', 'cloudCoverage']\n",
    "\n",
    "# # merge windVelocity in weatherData - no loss\n",
    "weatherDataColBo = weatherDataColBo.merge(windVelocityColBo, left_on=['Zeitstempel', \"SDO_ID\"], right_on=['Zeitstempel', \"SDO_ID\"])\n",
    "weatherDataColBo.columns = ['SDO_ID', 'Zeitstempel', 'airPressure', 'airTemperature', 'cloudCoverage', 'windVelocity']\n",
    "## merge precipitationAmount\n",
    "weatherDataColBo = weatherDataColBo.merge(precipitationAmountColBo, left_on=['Zeitstempel', \"SDO_ID\"], right_on=['Zeitstempel', \"SDO_ID\"])\n",
    "weatherDataColBo.columns = ['SDO_ID', 'Zeitstempel', 'airPressure', 'airTemperature', 'cloudCoverage', 'windVelocity', 'precipitationAmount']\n",
    "## merge relativeHumidity\n",
    "weatherDataColBo = weatherDataColBo.merge(relativeHumidityColBo, left_on=['Zeitstempel', \"SDO_ID\"], right_on=['Zeitstempel', \"SDO_ID\"])\n",
    "weatherDataColBo.columns = ['SDO_ID', 'Zeitstempel', 'airPressure', 'airTemperature', 'cloudCoverage', 'windVelocity', 'precipitationAmount','relativeHumidity']\n",
    "##merge soilTemperature \n",
    "weatherDataColBo = weatherDataColBo.merge(soilTemperatureColBo, left_on=['Zeitstempel', \"SDO_ID\"], right_on=['Zeitstempel', \"SDO_ID\"])\n",
    "weatherDataColBo.columns = ['SDO_ID', 'Zeitstempel', 'airPressure', 'airTemperature', 'cloudCoverage', 'windVelocity', 'precipitationAmount','relativeHumidity', 'soilTemperature']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging relevant weather datas for our correlation coefficient(Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge airPressure and airTemperature in weatherData\n",
    "weatherDataEss = airPressureEss.merge(airTemperatureEss, left_on=['Zeitstempel', 'SDO_ID'], right_on=['Zeitstempel', 'SDO_ID'])\n",
    "weatherDataEss.columns = ['SDO_ID', 'Zeitstempel', 'airPressure', 'airTemperature']\n",
    "#merge cloudCoverage in weatherData - loss of some entries -> Approach: Deletion - Missing Rows\n",
    "weatherDataEss = weatherDataEss.merge(cloudCoverageEss, left_on=['Zeitstempel', 'SDO_ID'], right_on=['Zeitstempel', 'SDO_ID'])\n",
    "weatherDataEss.columns = ['SDO_ID', 'Zeitstempel', 'airPressure', 'airTemperature', 'cloudCoverage']\n",
    "# merge windVelocity in weatherData - no loss\n",
    "weatherDataEss = weatherDataEss.merge(windVelocityEss, left_on=['Zeitstempel', \"SDO_ID\"], right_on=['Zeitstempel', \"SDO_ID\"])\n",
    "weatherDataEss.columns = ['SDO_ID', 'Zeitstempel', 'airPressure', 'airTemperature', 'cloudCoverage', 'windVelocity']\n",
    "# merge precipitationAmount\n",
    "weatherDataEss = weatherDataEss.merge(precipitationAmountEss, left_on=['Zeitstempel', \"SDO_ID\"], right_on=['Zeitstempel', \"SDO_ID\"])\n",
    "weatherDataEss.columns = ['SDO_ID', 'Zeitstempel', 'airPressure', 'airTemperature', 'cloudCoverage', 'windVelocity', 'precipitationAmount']\n",
    "# merge relativeHumidity\n",
    "weatherDataEss = weatherDataEss.merge(relativeHumidityEss, left_on=['Zeitstempel', \"SDO_ID\"], right_on=['Zeitstempel', \"SDO_ID\"])\n",
    "weatherDataEss.columns = ['SDO_ID', 'Zeitstempel', 'airPressure', 'airTemperature', 'cloudCoverage', 'windVelocity', 'precipitationAmount','relativeHumidity']\n",
    "# merge soilTemperature\n",
    "weatherDataEss = weatherDataEss.merge(soilTemperatureEss, left_on=['Zeitstempel', \"SDO_ID\"], right_on=['Zeitstempel', \"SDO_ID\"])\n",
    "weatherDataEss.columns = ['SDO_ID', 'Zeitstempel', 'airPressure', 'airTemperature', 'cloudCoverage', 'windVelocity', 'precipitationAmount','relativeHumidity','soilTemperature']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## computing percentage for the cologne bike fleet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporary dataframe for further manipulation\n",
    "cologne_bikes_frame = pd.DataFrame({'day':cologneCleanedData[\"day\"] ,\n",
    "                                    'time':cologneCleanedData[\"time\"] ,\n",
    "                                    'b_number':cologneCleanedData[\"b_number\"] ,\n",
    "                                    'hour':cologneCleanedData[\"hour\"]})\n",
    "cologne_bikes_frame['Datetime'] = cologne_bikes_frame.apply(lambda r : pd.datetime.combine(r['day'],r['time']),1)\n",
    "\n",
    "\n",
    "#computing absolute number of different bikes in the rental dataset\n",
    "cologne_numberOfBikes = cologne_bikes_frame.groupby(\"b_number\")[\"day\"].nunique()\n",
    "cNumberOfBikes = cologne_numberOfBikes.count()\n",
    "\n",
    "\n",
    "\n",
    "#grouping by combined datetime as hourly grouping\n",
    "cologne_bikesHourly = cologne_bikes_frame.groupby(pd.Grouper(key='Datetime', freq='H'))[\"b_number\"].nunique()\n",
    "cologne_bikesHourlyLength = cologne_bikesHourly.count()\n",
    "cologne_bikesHourly.iloc[0:24*cologne_bikesHourlyLength] = cologne_bikesHourly.iloc[0:24*cologne_bikesHourlyLength].apply(lambda x: x / cNumberOfBikes * 100)\n",
    "cologne_bikesHourly = cologne_bikesHourly.reset_index(level=['Datetime'])\n",
    "\n",
    "\n",
    "#adds the bikes, used in multiple hours to the following hours  \n",
    "c_tripTime  = pd.DataFrame({ 'day':cologneCleanedData[\"day\"] ,\n",
    "                            'hour':cologneCleanedData[\"hour\"],\n",
    "                       'trip_duration':cologneCleanedData[\"trip_duration\"] ,\n",
    "                         'Datetime':  cologne_bikes_frame['Datetime']})\n",
    "c_tripTime['Datetime'] = c_tripTime['Datetime'].map(timestampNormalize)\n",
    "c_tripTime['trip_time'] = (pd.Series(pd.to_timedelta(c_tripTime['trip_duration']))).dt.total_seconds()\n",
    "c_tripTime['length'] = c_tripTime['trip_time'].apply(lambda x: x/3600)\n",
    "c_tripTime['length'] = c_tripTime['length'].apply(np.floor)\n",
    "\n",
    "temp = 1\n",
    "while (temp < 3):\n",
    "    value = 0\n",
    "    tempV = c_tripTime[c_tripTime.length >= (temp)]\n",
    "    tempV = tempV.groupby(pd.Grouper(key='Datetime', freq='H')).agg('count')\n",
    "    tempV = tempV.reset_index(level = 'Datetime')\n",
    "    while (value < len(tempV)):\n",
    "        cologne_bikesHourly.loc[value ,'b_number'] =   cologne_bikesHourly.loc[value ,'b_number'] + (tempV.loc[value ,'length'] /cNumberOfBikes)\n",
    "        value+=1\n",
    "    temp += 1\n",
    "\n",
    "#computes range of the possible error created by bikes, which are only available in a part of the year\n",
    "#computing number of bikes with usage count smaller than x = 10 \n",
    "cologne_numberOfUsagePerBike = cologne_numberOfBikes.apply(lambda x: x < 10)\n",
    "cologne_numberOfUsagePerBike = len(cologne_numberOfUsagePerBike[cologne_numberOfUsagePerBike == True].index)\n",
    "cologne_percentageErrorRatio = cologne_numberOfUsagePerBike / cNumberOfBikes\n",
    "cologne_percentageErrorRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## computing percentage of the essen bike fleet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporary dataframe for further manipulation\n",
    "essen_bikes_frame = pd.DataFrame({'day':essenCleanedData[\"day\"] ,\n",
    "                                  'time':essenCleanedData[\"time\"],\n",
    "                                    'b_number':essenCleanedData[\"b_number\"] ,\n",
    "                                    'hour':essenCleanedData[\"hour\"]})\n",
    "essen_bikes_frame['Datetime'] = essen_bikes_frame.apply(lambda r : pd.datetime.combine(r['day'],r['time']),1)\n",
    "\n",
    "#computing absolute number of different bikes in the rental dataset\n",
    "essen_numberOfBikes = essen_bikes_frame.groupby(\"b_number\")[\"day\"].nunique()\n",
    "eNumberOfBikes = essen_numberOfBikes.count()\n",
    "\n",
    "#grouping by combined datetime as hourly grouping\n",
    "essen_bikesHourly = essen_bikes_frame.groupby(pd.Grouper(key='Datetime', freq='H'))[\"b_number\"].nunique()\n",
    "essen_bikesHourlyLength = essen_bikesHourly.count()\n",
    "essen_bikesHourly.iloc[0:24*essen_bikesHourlyLength] = essen_bikesHourly.iloc[0:24*essen_bikesHourlyLength].apply(lambda x: x / cNumberOfBikes * 100)\n",
    "essen_bikesHourly = essen_bikesHourly.reset_index(level=['Datetime'])\n",
    "\n",
    "#adds the bikes, used in multiple hours to the following hours  \n",
    "e_tripTime  = pd.DataFrame({ 'day':essenCleanedData[\"day\"] ,\n",
    "                            'hour':essenCleanedData[\"hour\"],\n",
    "                       'trip_duration':essenCleanedData[\"trip_duration\"] ,\n",
    "                         'Datetime':  essen_bikes_frame['Datetime']})\n",
    "e_tripTime['Datetime'] = e_tripTime['Datetime'].map(timestampNormalize)\n",
    "e_tripTime['trip_time'] = (pd.Series(pd.to_timedelta(e_tripTime['trip_duration']))).dt.total_seconds()\n",
    "e_tripTime['length'] = e_tripTime['trip_time'].apply(lambda x: x/3600)\n",
    "e_tripTime['length'] = e_tripTime['length'].apply(np.floor)\n",
    "\n",
    "temp = 1\n",
    "while (temp < 3):\n",
    "    value = 0\n",
    "    tempV = e_tripTime[e_tripTime.length >= (temp)]\n",
    "    tempV = tempV.groupby(pd.Grouper(key='Datetime', freq='H')).agg('count')\n",
    "    tempV = tempV.reset_index(level = 'Datetime')\n",
    "    while (value < len(tempV)):\n",
    "        essen_bikesHourly.loc[value ,'b_number'] =   essen_bikesHourly.loc[value ,'b_number'] + (tempV.loc[value ,'length'] /eNumberOfBikes)\n",
    "        value+=1\n",
    "    temp += 1\n",
    "\n",
    "#computes range of the possible error created by bikes, which are only available in a part of the year\n",
    "#computing number of bikes with usage count smaller than x = 10 \n",
    "essen_numberOfUsagePerBike = essen_numberOfBikes.apply(lambda x: x < 10)\n",
    "essen_numberOfUsagePerBike = len(essen_numberOfUsagePerBike[essen_numberOfUsagePerBike == True].index)\n",
    "essen_percentageErrorRatio = essen_numberOfUsagePerBike / eNumberOfBikes\n",
    "essen_percentageErrorRatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe with weather data and percentage of bikes used (Cologne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge weatherdataframe with utilizationdataframe\n",
    "DataCologne = cologne_bikesHourly.merge(weatherDataColBo, left_on=['Datetime'], right_on=['Zeitstempel'])\n",
    "\n",
    "DataCologne.sort_values(by=['Zeitstempel'], inplace=True)\n",
    "#drop not needed columns or double columns\n",
    "DataCologne = DataCologne.drop(columns=[\"Datetime\"])\n",
    "DataCologne = DataCologne.drop(columns=[\"SDO_ID\"])\n",
    "#rename columns\n",
    "DataCologne= DataCologne.rename(columns={\"b_number\":\"BikeUse\"})\n",
    "DataCologne\n",
    "#slice this df to the right datetime\n",
    "prA2_1=DataCologne[(DataCologne.Zeitstempel >= datetime(2019, 10, 1))&\n",
    "         (DataCologne.Zeitstempel < datetime(2019, 10, 8))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe with weather data and percentage of bikes used (Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge weatherdataframe with utilizationdataframe\n",
    "DataEssen = essen_bikesHourly.merge(weatherDataEss, left_on=['Datetime'], right_on=['Zeitstempel'])\n",
    "\n",
    "DataEssen.sort_values(by=['Zeitstempel'], inplace=True)\n",
    "#drop not needed columns or double columns\n",
    "DataEssen = DataEssen.drop(columns=[\"Datetime\"])\n",
    "DataEssen = DataEssen.drop(columns=[\"SDO_ID\"])\n",
    "#rename columns\n",
    "DataEssen= DataEssen.rename(columns={\"b_number\":\"BikeUse\"})\n",
    "#slice this df to the right datetime\n",
    "prA1_1=DataEssen[(DataEssen.Zeitstempel >= datetime(2019, 11, 1))&\n",
    "         (DataEssen.Zeitstempel < datetime(2019, 11, 4))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of used bikes/Utilization of a year (Cologne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cologne_bikesHourly.head()\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(80,4), dpi= 80)\n",
    "\n",
    "ax.plot(cologne_bikesHourly['Datetime'],cologne_bikesHourly[\"b_number\"])\n",
    "ax.set_xlabel(\"day\")\n",
    "ax.set_ylabel(\"used bikes in %\")\n",
    "ax.set_title(\"bike usage in % over the year\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of used bikes/Utilization of a year (Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essen_bikesHourly.head()\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(80,4), dpi= 80)\n",
    "\n",
    "ax.plot(essen_bikesHourly['Datetime'],essen_bikesHourly[\"b_number\"])\n",
    "ax.set_xlabel(\"day\")\n",
    "ax.set_ylabel(\"used bikes in %\")\n",
    "ax.set_title(\"bike usage in % over the year\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct comparison of both cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean = cologne_bikesHourly[\"b_number\"].rolling(window=20).mean()\n",
    "rolling_mean2 = essen_bikesHourly[\"b_number\"].rolling(window=20).mean()\n",
    "plt.figure(num=None, figsize=(30, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(cologne_bikesHourly['Datetime'], cologne_bikesHourly[\"b_number\"], label='Cologne percentage')\n",
    "plt.plot(cologne_bikesHourly['Datetime'], rolling_mean, label='Cologne percentage SMA', color='magenta')\n",
    "plt.plot(essen_bikesHourly['Datetime'], essen_bikesHourly[\"b_number\"], label=\"Essen percentage\")\n",
    "plt.plot(essen_bikesHourly['Datetime'], rolling_mean2, label='Essen percentage SMA', color='magenta')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"bike usage in % over the year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of used bikes for every hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following chart defines the final summary of the computed percentage data. It shows the mean values for every hour, the times of peak demand over a day and the fluctuation of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cologne_bikesHourly['hour'] = cologne_bikesHourly['Datetime'].map(hour_match)\n",
    "cologne = cologne_bikesHourly\n",
    "cologne['city'] = \"cologne\"\n",
    "cologne['percentage of used bikes'] = cologne['b_number']\n",
    "\n",
    "essen_bikesHourly['hour'] = essen_bikesHourly['Datetime'].map(hour_match)\n",
    "essen = essen_bikesHourly\n",
    "essen['city'] = \"essen\"\n",
    "essen['percentage of used bikes'] = essen['b_number']\n",
    "\n",
    "cities = [cologne,essen]\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(16, 10)\n",
    "\n",
    "plotOut = pd.concat(cities, axis=0, join='outer', ignore_index=False, keys=None,\n",
    "          levels=None, names=None, verify_integrity=False, copy=True)\n",
    "\n",
    "sns.boxplot(x=\"hour\",y=\"percentage of used bikes\",data= plotOut ,palette=\"rainbow\", hue=\"city\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Bikes Utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive graph for Bike Utilization (Cologne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interactive Graph to see exact utilization for a specific datetime\n",
    "pyo.init_notebook_mode()\n",
    "fig = px.line(cologne_bikesHourly, x='Datetime', y=\"b_number\",title=\"Utilization of a year, Cologne\")\n",
    "#create rangeslider for closer looks\n",
    "fig.update_xaxes(rangeslider_visible=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b_number = percentage of use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive graph for Bike Utilization (Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interactive Graph to see exact utilization for a specific datetime\n",
    "pyo.init_notebook_mode()\n",
    "fig = px.line(essen_bikesHourly, x='Datetime', y='b_number',title=\"Utilization of a year, Essen\")\n",
    "#create rangeslider for closer looks\n",
    "fig.update_xaxes(rangeslider_visible=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b_number = percentage of use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Weather Data combined with Utilization Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive graph comparing Temperature, Precipitation, Utilization (Cologne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with this interactive graph we can see the exact value for every hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enables plotly to work offline\n",
    "pyo.init_notebook_mode()\n",
    "fig = go.Figure()\n",
    "fig.add_scatter(x=DataCologne['Zeitstempel'], y=DataCologne['BikeUse'],name=\"BikeUse%\")\n",
    "fig.add_scatter(x=DataCologne['Zeitstempel'], y=DataCologne['airTemperature'],name=\"Airtemperature(C°)\")\n",
    "fig.add_scatter(x=DataCologne['Zeitstempel'], y=DataCologne['precipitationAmount'],name=\"Precipitation(mm)\")\n",
    "#create rangeslider for closer looks\n",
    "fig.update_xaxes(rangeslider_visible=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive graph comparing Temperature, Precipitation, Utilization (Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enables plotly to work offline\n",
    "pyo.init_notebook_mode()\n",
    "fig = go.Figure()\n",
    "fig.add_scatter(x=DataEssen['Zeitstempel'], y=DataEssen['BikeUse'],name=\"BikeUse%\")\n",
    "fig.add_scatter(x=DataEssen['Zeitstempel'], y=DataEssen['airTemperature'],name=\"Airtemperature\")\n",
    "fig.add_scatter(x=DataEssen['Zeitstempel'], y=DataEssen['precipitationAmount'],name=\"Precipitation\")\n",
    "#create rangeslider for closer looks\n",
    "fig.update_xaxes(rangeslider_visible=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## corrMatrix with Utilization & Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corrMatrix Cologne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These matrix shows every coefficient between each columns of the df. only the first/second row of the matrix is relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrMAtrix of whole year\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('corrMatrix/Year')\n",
    "corrMatrix_1c = DataCologne.corr()\n",
    "sns.heatmap(corrMatrix_1c, annot=True )\n",
    "plt.show()\n",
    "#corrMatrix of chosen time interval as an example\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Example corrMatrix/Interval')\n",
    "#restricted timeinterval from 2019-10-1 to 2019-10-8\n",
    "corrMatrix_2c = prA2_1.corr()\n",
    "sns.heatmap(corrMatrix_2c, annot=True )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corrMatrix Essen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrMAtrix of the whole year\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('corrMatrix/Year')\n",
    "corrMatrix = DataEssen.corr()\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.show()\n",
    "#corrMatrix of chosen time interval as an example\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Example corrMatrix/Interval')\n",
    "#restricted timeinterval from 2019-10-1 to 2019-10-8\n",
    "corrMatrix = prA1_1.corr()\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPI: Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some further preparations to calculate the revenue:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing a Dataframe with all the neccessary data to calculate revenue KPI's for Cologne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up a DataFrame with relevant data\n",
    "c_kpi_df = pd.DataFrame({'day':cologneData[\"day\"] ,\n",
    "                           'weekday2':cologneData[\"weekday2\"],\n",
    "                           'weekday':cologneData[\"weekday\"], \n",
    "                           'hour':cologneData[\"hour\"],\n",
    "                           'b_number':cologneData[\"b_number\"] ,\n",
    "                           'trip_duration':cologneData[\"trip_duration\"]})\n",
    "\n",
    "# get triptime (in sec) from trip duration \n",
    "c_duration_in_seconds = pd.Series(pd.to_timedelta(c_kpi_df['trip_duration']))\n",
    "c_kpi_df['trip_time'] = c_duration_in_seconds.dt.total_seconds()\n",
    "\n",
    "# caculate the cost of a trip using the pricing model of 1€/30min \n",
    "c_kpi_df['cost'] = c_kpi_df['trip_time'].apply(lambda x: x/1800+1)\n",
    "c_kpi_df['cost'] = c_kpi_df['cost'].apply(np.floor)\n",
    "\n",
    "# set a limit of maximum 9€ per trip (according to the Nextbike pricing model)\n",
    "c_kpi_df['cost'] = np.clip(c_kpi_df['cost'], a_max=9, a_min=None)\n",
    "\n",
    "# extract month name from date\n",
    "c_kpi_df['month'] =  pd.DatetimeIndex(c_kpi_df['day']).month\n",
    "import calendar\n",
    "c_kpi_df['month'] = c_kpi_df['month'].apply(lambda x: calendar.month_abbr[x])\n",
    "c_kpi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing a Dataframe with all the neccessary data to calculate revenue KPI's for Essen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up a DataFrame with relevant data\n",
    "e_kpi_df = pd.DataFrame({'day':essenData[\"day\"] ,\n",
    "                           'weekday2':essenData[\"weekday2\"],\n",
    "                           'weekday':essenData[\"weekday\"],\n",
    "                           'hour':essenData[\"hour\"],\n",
    "                           'b_number':essenData[\"b_number\"] ,\n",
    "                           'trip_duration':essenData[\"trip_duration\"]})\n",
    "\n",
    "# get triptime (in sec) from trip duration \n",
    "e_duration_in_seconds = pd.Series(pd.to_timedelta(e_kpi_df['trip_duration']))\n",
    "e_kpi_df['trip_time'] = e_duration_in_seconds.dt.total_seconds()\n",
    "\n",
    "# caculate the cost of a trip using the pricing model of 1€/30min \n",
    "e_kpi_df['cost'] = e_kpi_df['trip_time'].apply(lambda x: x/1800+1)\n",
    "e_kpi_df['cost'] = e_kpi_df['cost'].apply(np.floor)\n",
    "\n",
    "# set a limit of maximum 9€ per trip (according to the Nextbike pricing model)\n",
    "e_kpi_df['cost'] = np.clip(e_kpi_df['cost'], a_max=9, a_min=None)\n",
    "\n",
    "# extract month name from date\n",
    "e_kpi_df['month'] =  pd.DatetimeIndex(e_kpi_df['day']).month\n",
    "import calendar\n",
    "e_kpi_df['month'] = e_kpi_df['month'].apply(lambda x: calendar.month_abbr[x])\n",
    "e_kpi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revenue for Cologne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total revenue per hour (Cologne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total revenue generated per hour of the day over the whole time period in Cologne\n",
    "c_trip_cost_sum_per_hour = c_kpi_df.groupby('hour').cost.sum()\n",
    "c_trip_cost_sum_per_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the total revenue generated per hour of the day over the whole time period in Cologne\n",
    "fig,ax = plt.subplots(figsize=(12,4)) \n",
    "ax.plot(c_trip_cost_sum_per_hour)\n",
    "ax.set_xlim(0,23)\n",
    "ax.set_xticks(range(0,24))\n",
    "\n",
    "plt.xlabel('Hour of the day', fontsize=12)\n",
    "plt.ylabel('Revenue (in €)', fontsize=12)\n",
    "plt.title('Total Revenue per hour over the whole time period (Cologne)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Revenue per hour (Cologne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into numpy array, to perform mathematical operations\n",
    "c_trip_cost_sum_per_hour = np.array(c_trip_cost_sum_per_hour)\n",
    "\n",
    "# Average revenue per hour during a single day in Cologne\n",
    "# To get an idea how much revenue is generated on average per hour, we divide the total hourly revenue by the number of days \n",
    "\n",
    "c_avg_hourly_revenue = c_trip_cost_sum_per_hour/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the average revenue generated per hour of the day during a single day in Cologne\n",
    "fig,ax = plt.subplots(figsize=(12,4)) \n",
    "ax.plot(c_avg_hourly_revenue)\n",
    "ax.set_xlim(0,23)\n",
    "ax.set_xticks(range(0,24))\n",
    "\n",
    "plt.xlabel('Hour of the day', fontsize=12)\n",
    "plt.ylabel('Revenue (in €)', fontsize=12)\n",
    "plt.title('Average Revenue per hour during a single day (Cologne)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue per hour per bike (Cologne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue per hour per bike\n",
    "c_number_of_bikes = len(c_kpi_df[\"b_number\"].unique())\n",
    "print(\"The number of bikes in Cologne is:\", c_number_of_bikes)\n",
    "\n",
    "c_hourly_revenue_per_bike = c_trip_cost_sum_per_hour/c_number_of_bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the revenue generated per hour per bike in Cologne\n",
    "fig,ax = plt.subplots(figsize=(12,4)) \n",
    "ax.plot(c_hourly_revenue_per_bike)\n",
    "ax.set_xlim(0,23)\n",
    "ax.set_xticks(range(0,24))\n",
    "\n",
    "plt.xlabel('Hour of the day', fontsize=12)\n",
    "plt.ylabel('Revenue (in €)', fontsize=12)\n",
    "plt.title('Average Revenue per hour per bike (Cologne)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hourly revenue on weekends vs. workdays (Cologne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the revenue for weekdays vs weekends\n",
    "c_revenue_workday = c_kpi_df[c_kpi_df.weekday <= 5].groupby(\n",
    "                       c_kpi_df.hour).cost.sum()\n",
    "c_revenue_weekend = c_kpi_df[c_kpi_df.weekday > 5].groupby(\n",
    "                       c_kpi_df.hour).cost.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig,ax = plt.subplots(figsize=(12,4))\n",
    "# make the plot for Cologne\n",
    "ax.plot(c_revenue_workday, color=\"steelblue\", label=\"Workday\")\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Hour of the day\", fontsize=12)\n",
    "# show hours on the x-axis in 1-hour-steps\n",
    "ax.set_xlim(0,23)\n",
    "ax.set_xticks(range(0,24))\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Revenue workday (in €)\", color=\"steelblue\", fontsize=12)\n",
    "# show legend for Cologne\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# create twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(c_revenue_weekend,color=\"coral\", label=\"Weekend\")\n",
    "# set y-axis label\n",
    "ax2.set_ylabel(\"Revenue weekend (in €)\", color=\"coral\", fontsize=12)\n",
    "# set diagram title\n",
    "plt.title('Total hourly revenue on weekends vs. workdays (Cologne)', fontsize=14)\n",
    "# show legend for Cologne\n",
    "plt.legend(loc=\"upper right\")\n",
    "# display the diagram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue per weekday (Cologne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total revenue generated per day of the week over the whole time period in Cologne\n",
    "c_trip_cost_sum_per_weekday = c_kpi_df.groupby('weekday2').cost.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the weekdays in the right order\n",
    "c_trip_cost_sum_per_weekday = pd.DataFrame(c_trip_cost_sum_per_weekday)\n",
    "\n",
    "sorter = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "sorterIndex = dict(zip(sorter,range(len(sorter))))\n",
    "\n",
    "c_trip_cost_sum_per_weekday['day_id'] = c_trip_cost_sum_per_weekday.index\n",
    "c_trip_cost_sum_per_weekday['day_id'] = c_trip_cost_sum_per_weekday['day_id'].map(sorterIndex)\n",
    "c_trip_cost_sum_per_weekday.head(10)\n",
    "\n",
    "c_trip_cost_sum_per_weekday.sort_values('day_id', inplace=True)\n",
    "c_trip_cost_sum_per_weekday.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the total revenue generated per day of the week over the whole time period in Cologne\n",
    "fig,ax = plt.subplots(figsize=(12,4)) \n",
    "ax.plot(c_trip_cost_sum_per_weekday)\n",
    "\n",
    "# Set the range of the y-axis  \n",
    "ax.set_ylim(120000,200000)\n",
    "\n",
    "\n",
    "plt.xlabel('Day of the week', fontsize=12)\n",
    "plt.ylabel('Revenue (in €)', fontsize=12)\n",
    "plt.title('Total revenue per weekday (Cologne)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue per month (Cologne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total revenue generated per month in Cologne\n",
    "c_trip_cost_sum_per_month = c_kpi_df.groupby('month').cost.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the months in the right order\n",
    "c_trip_cost_sum_per_month = pd.DataFrame(c_trip_cost_sum_per_month)\n",
    "c_trip_cost_sum_per_month\n",
    "\n",
    "month_sorter = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "month_sorterIndex = dict(zip(month_sorter,range(len(month_sorter))))\n",
    "\n",
    "c_trip_cost_sum_per_month['month_id'] = c_trip_cost_sum_per_month.index\n",
    "c_trip_cost_sum_per_month['month_id'] = c_trip_cost_sum_per_month['month_id'].map(month_sorterIndex)\n",
    "c_trip_cost_sum_per_month.head(10)\n",
    "\n",
    "c_trip_cost_sum_per_month.sort_values('month_id', inplace=True)\n",
    "c_trip_cost_sum_per_month.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the total revenue generated per month in Cologne\n",
    "fig,ax = plt.subplots(figsize=(12,4)) \n",
    "ax.plot(c_trip_cost_sum_per_month)\n",
    "\n",
    "# Set the range of the y-axis  \n",
    "ax.set_ylim(60000,150000)\n",
    "\n",
    "\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Revenue (in €)', fontsize=12)\n",
    "plt.title('Revenue per month (Cologne)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revenue for Essen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total revenue per hour (Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total revenue generated per hour of the day over the whole time period in Essen\n",
    "e_trip_cost_sum_per_hour = e_kpi_df.groupby('hour').cost.sum()\n",
    "e_trip_cost_sum_per_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the total revenue generated per hour of the day over the whole time period in Essen\n",
    "fig,ax = plt.subplots(figsize=(12,4)) \n",
    "ax.plot(e_trip_cost_sum_per_hour)\n",
    "ax.set_xlim(0,23)\n",
    "ax.set_xticks(range(0,24))\n",
    "\n",
    "plt.xlabel('Hour of the day', fontsize=12)\n",
    "plt.ylabel('Revenue (in €)', fontsize=12)\n",
    "plt.title('Total revenue per hour over the whole time period (Essen)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Revenue per hour (Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into numpy array, to perform mathematical operations\n",
    "e_trip_cost_sum_per_hour = np.array(e_trip_cost_sum_per_hour)\n",
    "\n",
    "# Average revenue per hour during a single day in Essen\n",
    "# To get an idea how much revenue is generated on average per hour, we divide the total hourly revenue by the number of days \n",
    "\n",
    "e_avg_hourly_revenue = e_trip_cost_sum_per_hour/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the average revenue generated per hour of the day during a single day in Essen\n",
    "fig,ax = plt.subplots(figsize=(12,4)) \n",
    "ax.plot(e_avg_hourly_revenue)\n",
    "ax.set_xlim(0,23)\n",
    "ax.set_xticks(range(0,24))\n",
    "\n",
    "plt.xlabel('Hour of the day', fontsize=12)\n",
    "plt.ylabel('Revenue (in €)', fontsize=12)\n",
    "plt.title('Average revenue per hour during a single day (Essen)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue per hour per bike (Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue per hour per bike\n",
    "e_number_of_bikes = len(e_kpi_df[\"b_number\"].unique())\n",
    "print(\"The number of bikes in Essen is:\", e_number_of_bikes)\n",
    "\n",
    "e_hourly_revenue_per_bike = e_trip_cost_sum_per_hour/e_number_of_bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the revenue generated per hour per bike in Essen\n",
    "fig,ax = plt.subplots(figsize=(12,4)) \n",
    "ax.plot(e_hourly_revenue_per_bike)\n",
    "ax.set_xlim(0,23)\n",
    "ax.set_xticks(range(0,24))\n",
    "\n",
    "plt.xlabel('Hour of the day', fontsize=12)\n",
    "plt.ylabel('Revenue (in €)', fontsize=12)\n",
    "plt.title('Average Revenue per hour per bike (Essen)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hourly revenue on weekends vs. workdays (Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the revenue for weekdays vs weekends\n",
    "e_revenue_workday = e_kpi_df[e_kpi_df.weekday <= 5].groupby(\n",
    "                       e_kpi_df.hour).cost.sum()\n",
    "e_revenue_weekend = e_kpi_df[e_kpi_df.weekday > 5].groupby(\n",
    "                       e_kpi_df.hour).cost.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig,ax = plt.subplots(figsize=(12,4))\n",
    "# make the plot for Cologne\n",
    "ax.plot(e_revenue_workday, color=\"steelblue\", label=\"Workday\")\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Hour of the day\", fontsize=12)\n",
    "# show hours on the x-axis in 1-hour-steps\n",
    "ax.set_xlim(0,23)\n",
    "ax.set_xticks(range(0,24))\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Revenue workday (in €)\", color=\"steelblue\", fontsize=12)\n",
    "# show legend for Cologne\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# create twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(e_revenue_weekend,color=\"coral\", label=\"Weekend\")\n",
    "# set y-axis label\n",
    "ax2.set_ylabel(\"Revenue weekend (in €)\", color=\"coral\", fontsize=12)\n",
    "# set diagram title\n",
    "plt.title('Total hourly revenue on weekends vs. workdays (Essen)', fontsize=14)\n",
    "# show legend for Cologne\n",
    "plt.legend(loc=\"upper right\")\n",
    "# display the diagram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue per weekday (Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total revenue generated per day of the week over the whole time period in Essen\n",
    "e_trip_cost_sum_per_weekday = e_kpi_df.groupby('weekday2').cost.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the weekdays in the right order\n",
    "e_trip_cost_sum_per_weekday = pd.DataFrame(e_trip_cost_sum_per_weekday)\n",
    "\n",
    "sorter = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "sorterIndex = dict(zip(sorter,range(len(sorter))))\n",
    "\n",
    "e_trip_cost_sum_per_weekday['day_id'] = e_trip_cost_sum_per_weekday.index\n",
    "e_trip_cost_sum_per_weekday['day_id'] = e_trip_cost_sum_per_weekday['day_id'].map(sorterIndex)\n",
    "e_trip_cost_sum_per_weekday.head(10)\n",
    "\n",
    "e_trip_cost_sum_per_weekday.sort_values('day_id', inplace=True)\n",
    "e_trip_cost_sum_per_weekday.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the total revenue generated per day of the week over the whole time period in Essen\n",
    "fig,ax = plt.subplots(figsize=(12,4)) \n",
    "ax.plot(e_trip_cost_sum_per_weekday)\n",
    "\n",
    "# Set the range of the y-axis  \n",
    "ax.set_ylim(5000,14000)\n",
    "\n",
    "\n",
    "plt.xlabel('Day of the week', fontsize=12)\n",
    "plt.ylabel('Revenue (in €)', fontsize=12)\n",
    "plt.title('Total Revenue per weekday over the whole time period (Essen)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue per month (Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total revenue generated per month in Essen\n",
    "e_trip_cost_sum_per_month = e_kpi_df.groupby('month').cost.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the months in the right order\n",
    "e_trip_cost_sum_per_month = pd.DataFrame(e_trip_cost_sum_per_month)\n",
    "e_trip_cost_sum_per_month\n",
    "\n",
    "month_sorter = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "month_sorterIndex = dict(zip(month_sorter,range(len(month_sorter))))\n",
    "\n",
    "e_trip_cost_sum_per_month['month_id'] = e_trip_cost_sum_per_month.index\n",
    "e_trip_cost_sum_per_month['month_id'] = e_trip_cost_sum_per_month['month_id'].map(month_sorterIndex)\n",
    "e_trip_cost_sum_per_month.head(10)\n",
    "\n",
    "e_trip_cost_sum_per_month.sort_values('month_id', inplace=True)\n",
    "e_trip_cost_sum_per_month.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the total revenue generated per month in Essen\n",
    "fig,ax = plt.subplots(figsize=(12,4)) \n",
    "ax.plot(e_trip_cost_sum_per_month)\n",
    "\n",
    "# Set the range of the y-axis  \n",
    "ax.set_ylim(2000,10000)\n",
    "\n",
    "\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Revenue (in €)', fontsize=12)\n",
    "plt.title('Revenue per month (Essen)', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revenue Comparison Cologne vs. Essen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this last section on the revenue KPI's we are going to directly compare the results for both cities.\n",
    "\n",
    "Since the total revenue for Cologne is much higher than for Essen (it's about 17 times as high), we need to adjust the way we display the data within a single diagram. \n",
    "In this case we chose to use a lineplot with two different y-axis - one for Cologne and one for Essen.\n",
    "This enables us to nicely spot the differences of the two cities for the given timeframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Revenue for Cologne\n",
    "c_total_revenue = c_kpi_df['cost'].sum()\n",
    "print(\"The total revenue generated in Cologne is:\", c_total_revenue, \"€\")\n",
    "\n",
    "# Total Revenue for Essen FEHLT NOCH -> erstmal e_tripTime berechnen\n",
    "e_total_revenue = e_kpi_df['cost'].sum()\n",
    "print(\"The total revenue generated in Essen is:\", e_total_revenue, \"€\")\n",
    "\n",
    "scale_factor = c_total_revenue/e_total_revenue\n",
    "print(\"The total revenue generated in Cologne is\",scale_factor, \"times higher than in Essen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total revenue per hour (Cologne vs. Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total revenue generated per bike in Cologne\n",
    "c_revenue_per_bike = c_total_revenue/c_number_of_bikes\n",
    "\n",
    "# Calculate the total revenue generated per bike in Cologne\n",
    "e_revenue_per_bike = e_total_revenue/e_number_of_bikes\n",
    "\n",
    "print(\"The revenue generated per bike in Cologne is\", c_revenue_per_bike, \"€.\")\n",
    "print(\"The revenue generated per bike in Essen is\", e_revenue_per_bike, \"€.\")\n",
    "\n",
    "revenue_per_bike_diff = c_revenue_per_bike/e_revenue_per_bike\n",
    "print(\"The revenue generated per bike in Cologne is\", revenue_per_bike_diff, \"times higher than in Essen.\")\n",
    "\n",
    "# create figure and axis objects with subplots()\n",
    "fig,ax = plt.subplots(figsize=(12,4))\n",
    "# make the plot for Cologne\n",
    "ax.plot(c_trip_cost_sum_per_hour, color=\"steelblue\", label=\"Cologne\")\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Hour of the day\", fontsize=12)\n",
    "# show hours on the x-axis in 1-hour-steps\n",
    "ax.set_xlim(0,23)\n",
    "ax.set_xticks(range(0,24))\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Revenue in Cologne (in €)\", color=\"steelblue\", fontsize=12)\n",
    "# show legend for Cologne\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# create twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(e_trip_cost_sum_per_hour,color=\"coral\", label=\"Essen\")\n",
    "# set y-axis label\n",
    "ax2.set_ylabel(\"Revenue in Essen (in €)\", color=\"coral\", fontsize=12)\n",
    "# set diagram title\n",
    "plt.title('Total Revenue per hour of the day (Cologne vs. Essen)', fontsize=14)\n",
    "# show legend for Cologne\n",
    "plt.legend(loc=\"upper right\")\n",
    "# display the diagram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average revenue per hour (Cologne vs. Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig,ax = plt.subplots(figsize=(12,4))\n",
    "# make the plot for Cologne\n",
    "ax.plot(c_avg_hourly_revenue, color=\"steelblue\", label=\"Cologne\")\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Hour of the day\", fontsize=12)\n",
    "# show hours on the x-axis in 1-hour-steps\n",
    "ax.set_xlim(0,23)\n",
    "ax.set_xticks(range(0,24))\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Revenue in Cologne (in €)\", color=\"steelblue\", fontsize=12)\n",
    "# show legend for Cologne\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# create twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(e_avg_hourly_revenue,color=\"coral\", label=\"Essen\")\n",
    "# set y-axis label\n",
    "ax2.set_ylabel(\"Revenue in Essen (in €)\", color=\"coral\", fontsize=12)\n",
    "# set diagram title\n",
    "plt.title('Avergae Revenue per hour for a single day (Cologne vs. Essen)', fontsize=14)\n",
    "# show legend for Cologne\n",
    "plt.legend(loc=\"upper right\")\n",
    "# display the diagram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue per hour per bike (Cologne vs. Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig,ax = plt.subplots(figsize=(12,4))\n",
    "# make the plot for Cologne\n",
    "ax.plot(c_hourly_revenue_per_bike, color=\"steelblue\", label=\"Cologne\")\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Hour of the day\", fontsize=12)\n",
    "# show hours on the x-axis in 1-hour-steps\n",
    "ax.set_xlim(0,23)\n",
    "ax.set_xticks(range(0,24))\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Revenue in Cologne (in €)\", color=\"steelblue\", fontsize=12)\n",
    "# show legend for Cologne\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# create twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(e_hourly_revenue_per_bike,color=\"coral\", label=\"Essen\")\n",
    "# set y-axis label\n",
    "ax2.set_ylabel(\"Revenue in Essen (in €)\", color=\"coral\", fontsize=12)\n",
    "# set diagram title\n",
    "plt.title('Revenue per hour per bike (Cologne vs. Essen)', fontsize=14)\n",
    "# show legend for Cologne\n",
    "plt.legend(loc=\"upper right\")\n",
    "# display the diagram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hourly revenue on weekend vs. workdays (Cologne vs. Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig,ax = plt.subplots(figsize=(12,4))\n",
    "# make the plot for Cologne\n",
    "ax.plot(c_revenue_workday, color=\"steelblue\", label=\"Cologne\")\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Hour of the day\", fontsize=12)\n",
    "# show hours on the x-axis in 1-hour-steps\n",
    "ax.set_xlim(0,23)\n",
    "ax.set_xticks(range(0,24))\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Revenue Cologne (in €)\", color=\"steelblue\", fontsize=12)\n",
    "# show legend for Cologne\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# create twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(e_revenue_workday,color=\"coral\", label=\"Essen\")\n",
    "# set y-axis label\n",
    "ax2.set_ylabel(\"Revenue Essen (in €)\", color=\"coral\", fontsize=12)\n",
    "# set diagram title\n",
    "plt.title('Total hourly revenue on workdays (Cologne vs. Essen)', fontsize=14)\n",
    "# show legend for Cologne\n",
    "plt.legend(loc=\"upper right\")\n",
    "# display the diagram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig,ax = plt.subplots(figsize=(12,4))\n",
    "# make the plot for Cologne\n",
    "ax.plot(c_revenue_weekend, color=\"steelblue\", label=\"Cologne\")\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Hour of the day\", fontsize=12)\n",
    "# show hours on the x-axis in 1-hour-steps\n",
    "ax.set_xlim(0,23)\n",
    "ax.set_xticks(range(0,24))\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Revenue Cologne (in €)\", color=\"steelblue\", fontsize=12)\n",
    "# show legend for Cologne\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "# create twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(e_revenue_weekend,color=\"coral\", label=\"Essen\")\n",
    "# set y-axis label\n",
    "ax2.set_ylabel(\"Revenue Essen (in €)\", color=\"coral\", fontsize=12)\n",
    "# set diagram title\n",
    "plt.title('Total hourly revenue on weekends (Cologne vs. Essen)', fontsize=14)\n",
    "# show legend for Cologne\n",
    "plt.legend(loc=\"upper right\")\n",
    "# display the diagram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue per week (Cologne vs. Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig,ax = plt.subplots(figsize=(12,4))\n",
    "# make the plot for Cologne\n",
    "ax.plot(c_trip_cost_sum_per_weekday, color=\"steelblue\", label=\"Cologne\")\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Weekday\", fontsize=12)\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Revenue in Cologne (in €)\", color=\"steelblue\", fontsize=12)\n",
    "# Set the range of the y-axis  \n",
    "ax.set_ylim(130000,200000)\n",
    "\n",
    "# create twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(e_trip_cost_sum_per_weekday,color=\"coral\", label=\"Essen\")\n",
    "# set y-axis label\n",
    "ax2.set_ylabel(\"Revenue in Essen (in €)\", color=\"coral\", fontsize=12)\n",
    "# Set the range of the y-axis  \n",
    "ax2.set_ylim(6000,13000)\n",
    "# set diagram title\n",
    "plt.title('Revenue per weekday (Cologne vs. Essen)', fontsize=14)\n",
    "# display the diagram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revenue per month (Cologne vs. Essen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axis objects with subplots()\n",
    "fig,ax = plt.subplots(figsize=(12,4))\n",
    "# make the plot for Cologne\n",
    "ax.plot(c_trip_cost_sum_per_month, color=\"steelblue\", label=\"Cologne\")\n",
    "# set x-axis label\n",
    "ax.set_xlabel(\"Month\", fontsize=12)\n",
    "# set y-axis label\n",
    "ax.set_ylabel(\"Revenue in Cologne (in €)\", color=\"steelblue\", fontsize=12)\n",
    "# Set the range of the y-axis  \n",
    "ax.set_ylim(70000,140000)\n",
    "\n",
    "# create twin object for two different y-axis on the sample plot\n",
    "ax2=ax.twinx()\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(e_trip_cost_sum_per_month,color=\"coral\", label=\"Essen\")\n",
    "# set y-axis label\n",
    "ax2.set_ylabel(\"Revenue in Essen (in €)\", color=\"coral\", fontsize=12)\n",
    "# Set the range of the y-axis  \n",
    "ax2.set_ylim(2000,10000)\n",
    "# set diagram title\n",
    "plt.title('Revenue per month (Cologne vs. Essen)', fontsize=14)\n",
    "# display the diagram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPI: Coverage and peak demand of bikes per borough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the Dataframes for Cologne and Essen for Start and Destination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define some Dataframes, on which the computing process will depend. Furthermore we import the Shapefiles containing the location and shape of the boroughs, which we need for our visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_boroughs = gpd.read_file(\"Stadtteil/Essen-Stadtteile-map2.shp\")\n",
    "e_boroughs = e_boroughs.drop(['boundary', 'type' , 'source' , 'wikipedia' , 'admin_leve' , 'ref'], axis =1)\n",
    "e_boroughs = e_boroughs.reset_index()\n",
    "e_boroughs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_boroughs = gpd.read_file(\"Stadtteil/Stadtteil_WGS84.shp\")\n",
    "c_boroughs2 = gpd.read_file(\"Stadtteil/Stadtteil.shp\")\n",
    "c_boroughs['name'] = c_boroughs2['STT_NAME']\n",
    "c_boroughs = c_boroughs.drop(['STT_NAME', 'SHAPE_AREA' , 'SHAPE_LEN' , 'STT_NR'], axis =1)\n",
    "c_boroughs = c_boroughs.reset_index()\n",
    "c_boroughs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cologne_timedGeo =  pd.DataFrame({ 'Zeitstempel':cologneCleanedData[\"Zeitstempel\"] ,\n",
    "                                  'hour' : cologneCleanedData[\"hour\"] ,\n",
    "                       'b_number':cologneCleanedData[\"b_number\"] ,\n",
    "                       'orig_lat':cologneCleanedData[\"orig_lat\"] ,\n",
    "                       'orig_lng':cologneCleanedData[\"orig_lng\"] ,\n",
    "                       'dest_lat':cologneCleanedData[\"dest_lat\"] ,\n",
    "                       'dest_lng':cologneCleanedData[\"dest_lng\"] })\n",
    "cologne_timedGeo['dest_lat'] = cologne_timedGeo['dest_lat'].round(decimals = 5)\n",
    "cologne_timedGeo['dest_lng'] = cologne_timedGeo['dest_lng'].round(decimals = 5)\n",
    "cologne_timedGeo['orig_lat'] = cologne_timedGeo['orig_lat'].round(decimals = 5)\n",
    "cologne_timedGeo['orig_lng'] = cologne_timedGeo['orig_lng'].round(decimals = 5)\n",
    "\n",
    "cologne_timedGeo1 = pd.DataFrame({ 'Zeitstempel':cologneCleanedData[\"Zeitstempel\"] ,\n",
    "                                  'hour' : cologneCleanedData[\"hour\"] ,\n",
    "                       'b_number':cologneCleanedData[\"b_number\"] ,\n",
    "                       'orig_lat':cologneCleanedData[\"orig_lat\"] ,\n",
    "                       'orig_lng':cologneCleanedData[\"orig_lng\"] ,\n",
    "                       'dest_lat':cologneCleanedData[\"dest_lat\"] ,\n",
    "                       'dest_lng':cologneCleanedData[\"dest_lng\"] })\n",
    "cologne_timedGeo1['dest_lat'] = cologne_timedGeo1['dest_lat'].round(decimals = 5)\n",
    "cologne_timedGeo1['dest_lng'] = cologne_timedGeo1['dest_lng'].round(decimals = 5)\n",
    "cologne_timedGeo1['orig_lat'] = cologne_timedGeo1['orig_lat'].round(decimals = 5)\n",
    "cologne_timedGeo1['orig_lng'] = cologne_timedGeo1['orig_lng'].round(decimals = 5)\n",
    "\n",
    "cologne_timedGeo_orig = gpd.GeoDataFrame(cologne_timedGeo , geometry= gpd.points_from_xy(cologne_timedGeo.orig_lng ,cologne_timedGeo.orig_lat))\n",
    "cologne_timedGeo_dest = gpd.GeoDataFrame(cologne_timedGeo1 , geometry= gpd.points_from_xy(cologne_timedGeo1.dest_lng ,cologne_timedGeo1.dest_lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essen_timedGeo =  pd.DataFrame({ 'Zeitstempel':essenCleanedData[\"Zeitstempel\"] ,\n",
    "                                'hour' : essenCleanedData[\"hour\"] ,\n",
    "                       'b_number':essenCleanedData[\"b_number\"] ,\n",
    "                       'orig_lat':essenCleanedData[\"orig_lat\"] ,\n",
    "                       'orig_lng':essenCleanedData[\"orig_lng\"] ,\n",
    "                       'dest_lat':essenCleanedData[\"dest_lat\"] ,\n",
    "                       'dest_lng':essenCleanedData[\"dest_lng\"] })\n",
    "essen_timedGeo['dest_lat'] = essen_timedGeo['dest_lat'].round(decimals = 5)\n",
    "essen_timedGeo['dest_lng'] = essen_timedGeo['dest_lng'].round(decimals = 5)\n",
    "essen_timedGeo['orig_lat'] = essen_timedGeo['orig_lat'].round(decimals = 5)\n",
    "essen_timedGeo['orig_lng'] = essen_timedGeo['orig_lng'].round(decimals = 5)\n",
    "\n",
    "essen_timedGeo1 = pd.DataFrame({ 'Zeitstempel':essenCleanedData[\"Zeitstempel\"] ,\n",
    "                                'hour' : essenCleanedData[\"hour\"] ,\n",
    "                       'b_number':essenCleanedData[\"b_number\"] ,\n",
    "                       'orig_lat':essenCleanedData[\"orig_lat\"] ,\n",
    "                       'orig_lng':essenCleanedData[\"orig_lng\"] ,\n",
    "                       'dest_lat':essenCleanedData[\"dest_lat\"] ,\n",
    "                       'dest_lng':essenCleanedData[\"dest_lng\"] })\n",
    "essen_timedGeo1['dest_lat'] = essen_timedGeo1['dest_lat'].round(decimals = 5)\n",
    "essen_timedGeo1['dest_lng'] = essen_timedGeo1['dest_lng'].round(decimals = 5)\n",
    "essen_timedGeo1['orig_lat'] = essen_timedGeo1['orig_lat'].round(decimals = 5)\n",
    "essen_timedGeo1['orig_lng'] = essen_timedGeo1['orig_lng'].round(decimals = 5)\n",
    "\n",
    "essen_timedGeo_orig = gpd.GeoDataFrame(essen_timedGeo , geometry= gpd.points_from_xy(essen_timedGeo.orig_lng ,essen_timedGeo.orig_lat))\n",
    "essen_timedGeo_dest = gpd.GeoDataFrame(essen_timedGeo1 , geometry= gpd.points_from_xy(essen_timedGeo1.dest_lng ,essen_timedGeo1.dest_lat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the functions used to compute the KPI values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are used to compute the following for both cities individually:\n",
    "\n",
    "    1) the percentage of used bikes in all boroughs as a mean value for an hour over the year\n",
    "    2) matching a point in geopandas format in the boroughs of a city\n",
    "    3) the percentage of used bikes in all boroughs for one individual hour of the year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_for_hour_diff_plot (hours , dataframeStart, dataframeDestination , boroughs , scheme_diff , city):\n",
    "    x = dataframeStart[dataframeStart['hour'] == hours]\n",
    "    x = x.drop('hour' , axis=1)\n",
    "    x = x.set_index('index')\n",
    "    bike = x['index_right'].rename('number_of_bikes')\n",
    "    combined_with_boroughStart = pd.merge(boroughs, bike, how='outer', on=None, left_on=None, right_on=None,\n",
    "    left_index=True, right_index=True, sort=True)\n",
    "    combined_with_boroughStart['number_of_bikes'] = combined_with_boroughStart['number_of_bikes'].fillna(0)\n",
    "    bikes_in_hour = combined_with_boroughStart.number_of_bikes.sum()\n",
    "    combined_with_boroughStart.number_of_bikes = combined_with_boroughStart.number_of_bikes.apply(lambda x: x/bikes_in_hour*100)\n",
    "    combined_with_boroughStart['number_of_bikes'] = combined_with_boroughStart['number_of_bikes'].fillna(0)\n",
    "    \n",
    "    y = dataframeDestination[dataframeDestination['hour'] == hours]\n",
    "    y = y.drop('hour' , axis=1)\n",
    "    y = y.set_index('index')\n",
    "    bike = y['index_right'].rename('number_of_bikes')\n",
    "    combined_with_boroughDest = pd.merge(boroughs, bike, how='outer', on=None, left_on=None, right_on=None,\n",
    "    left_index=True, right_index=True, sort=True)\n",
    "    combined_with_boroughDest['number_of_bikes'] = combined_with_boroughDest['number_of_bikes'].fillna(0)\n",
    "    bikes_in_hour = combined_with_boroughDest.number_of_bikes.sum()\n",
    "    combined_with_boroughDest.number_of_bikes = combined_with_boroughDest.number_of_bikes.apply(lambda x: x/bikes_in_hour*100)\n",
    "    combined_with_boroughDest['number_of_bikes'] = combined_with_boroughDest['number_of_bikes'].fillna(0)\n",
    "    \n",
    "    diff = combined_with_boroughStart['number_of_bikes']-combined_with_boroughDest['number_of_bikes']\n",
    "    combined_with_boroughStart['number_of_bikes'] = diff\n",
    "    \n",
    "    if ((hours == 0) &  (city == 'cologne')):\n",
    "        scheme_diff = mapclassify.Quantiles(diff, k=20)\n",
    "    \n",
    "    plot_of_map = combined_with_boroughStart.number_of_bikes\n",
    "    plot = geoplot.choropleth(\n",
    "        combined_with_boroughStart, hue=plot_of_map, scheme=scheme_diff,\n",
    "        cmap='Reds', figsize=(50, 60) , legend = True\n",
    "    )\n",
    "    plot = plot.set_title('Mean change of bike availability per borough at ' + str(hours) + \" o'clock\")\n",
    "    for i in range(0,len(combined_with_boroughStart)):\n",
    "        combined_with_boroughStart.loc[i,'centroid_lon'] = combined_with_boroughStart.geometry.centroid.x.iloc[i]\n",
    "        combined_with_boroughStart.loc[i,'centroid_lat'] = combined_with_boroughStart.geometry.centroid.y.iloc[i]\n",
    "        plt.text(combined_with_boroughStart.loc[i,'centroid_lon'],combined_with_boroughStart.loc[i,'centroid_lat'],combined_with_boroughStart.loc[i,'name']\n",
    "                , horizontalalignment='center', verticalalignment ='center' ,bbox=dict(facecolor='white', alpha=0.5))\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_Points_to_boroughs(city , df):\n",
    "    if('cologne' == city):\n",
    "        bikes_in_boroughs = gpd.sjoin(df, c_boroughs, how=\"inner\", op='intersects')\n",
    "        rented_bikes_in_boroughs = bikes_in_boroughs.set_index('index_right')\n",
    "    elif('essen' == city):\n",
    "        bikes_in_boroughs = gpd.sjoin(df, e_boroughs, how=\"inner\", op='intersects')\n",
    "        rented_bikes_in_boroughs = bikes_in_boroughs.set_index('index_right')\n",
    "    return rented_bikes_in_boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_PNOB_city_date (city , date , rented_bikes_in_boroughs , boroughs):\n",
    "    bikes = rented_bikes_in_boroughs[(rented_bikes_in_boroughs['Zeitstempel'] == date)]\n",
    "    bikes = bikes.groupby('index_right')['index'].count()\n",
    "    bike = bikes.rename('number_of_bikes')\n",
    "    combined_with_borough = pd.merge(boroughs, bike, how='outer', on=None, left_on=None, right_on=None,\n",
    "    left_index=True, right_index=True, sort=True)\n",
    "    combined_with_borough['number_of_bikes'] = combined_with_borough['number_of_bikes'].fillna(0)\n",
    "    bikes_in_hour = combined_with_borough.number_of_bikes.sum()\n",
    "    combined_with_borough.number_of_bikes = combined_with_borough.number_of_bikes.apply(lambda x: x/bikes_in_hour*100)\n",
    "    combined_with_borough['number_of_bikes'] = combined_with_borough['number_of_bikes'].fillna(0)\n",
    "    return combined_with_borough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the 24 hour mean-values over the year for cologne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a good visualization we observe the differences between our bikes start and end location. This can be achieved with the function defined above. The exact scheme will be the same for each function to increase compareability. In the following we see first two maps containing the start and end distribution of bikes over the boroughs. After this there are 24 maps each showing a different hour computed as a mean value over the year. The same will be done for the data of essen afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.datetime.strptime('2019-07-13 11:00:00', '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cologne_timedGeo_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the trips are matched to the boroughs and the number of bikes per borough is counted\n",
    "rented_bikes_in_boroughs_Start = match_Points_to_boroughs('cologne', cologne_timedGeo_orig)\n",
    "rbibs = rented_bikes_in_boroughs_Start\n",
    "c_validity_S = rbibs.groupby('name').count()\n",
    "rented_bikes_in_boroughs_Dest = match_Points_to_boroughs('cologne', cologne_timedGeo_dest)\n",
    "rbibd = rented_bikes_in_boroughs_Dest\n",
    "c_validity_D = rbibd.groupby('name').count()\n",
    "cbS = compute_PNOB_city_date ('cologne' , date , rented_bikes_in_boroughs_Start , c_boroughs)\n",
    "cbD = compute_PNOB_city_date ('cologne' , date , rented_bikes_in_boroughs_Dest , c_boroughs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this value shows the number of boroughs where there was no rental activity at all. \n",
    "c_validity = c_validity_S.merge(c_validity_D, left_on='name', right_on='name')\n",
    "print(len(c_boroughs) - len (c_validity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this scheme is used in all following similar maps to make them comparable\n",
    "scheme_oneHour = mapclassify.Quantiles(cbS.number_of_bikes, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the map of the renting in Cologne\n",
    "plot_of_map = cbS.number_of_bikes\n",
    "plot = geoplot.choropleth(\n",
    "    cbS, hue=plot_of_map, scheme=scheme_oneHour,\n",
    "    cmap='Reds', figsize=(50, 60) , legend = True\n",
    ")\n",
    "plot = plot.set_title('Distribution of tripstarts at ' + str(date)+ \"(Cologne)\")\n",
    "for i in range(0,len(cbS)):\n",
    "    cbS.loc[i,'centroid_lon'] = cbS.geometry.centroid.x.iloc[i]\n",
    "    cbS.loc[i,'centroid_lat'] = cbS.geometry.centroid.y.iloc[i]\n",
    "    plt.text(cbS.loc[i,'centroid_lon'],cbS.loc[i,'centroid_lat'],cbS.loc[i,'name']\n",
    "             , horizontalalignment='center', verticalalignment ='center' ,bbox=dict(facecolor='white', alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the map of the returning of bikes in Cologne\n",
    "plot_of_map = cbD.number_of_bikes\n",
    "plot = geoplot.choropleth(\n",
    "    cbD, hue=plot_of_map, scheme=scheme_oneHour,\n",
    "    cmap='Reds', figsize=(50, 60) , legend = True\n",
    ")\n",
    "plot = plot.set_title('Distribution of tripdestinations at ' + str(date)+ \"(Cologne)\")\n",
    "for i in range(0,len(cbD)):\n",
    "    cbD.loc[i,'centroid_lon'] = cbD.geometry.centroid.x.iloc[i]\n",
    "    cbD.loc[i,'centroid_lat'] = cbD.geometry.centroid.y.iloc[i]\n",
    "    plt.text(cbD.loc[i,'centroid_lon'],cbD.loc[i,'centroid_lat'],cbD.loc[i,'name']\n",
    "             , horizontalalignment='center', verticalalignment ='center' ,bbox=dict(facecolor='white', alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#here all trips are matched to two mapcharts\n",
    "cologne_timedGeo_orig = gpd.sjoin(cologne_timedGeo_orig, c_boroughs, how=\"inner\", op='intersects')\n",
    "cologne_timedGeo_orig = cologne_timedGeo_orig.groupby(['hour' , 'index'])['index_right'].count()\n",
    "cologne_timedGeo_orig = cologne_timedGeo_orig.reset_index()\n",
    "cologne_timedGeo_dest = gpd.sjoin(cologne_timedGeo_dest, c_boroughs, how=\"inner\", op='intersects')\n",
    "cologne_timedGeo_dest = cologne_timedGeo_dest.groupby(['hour' , 'index'])['index_right'].count()\n",
    "cologne_timedGeo_dest = cologne_timedGeo_dest.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the differences between the renting and return activity will now be plotted for each hour of the year using mean values\n",
    "hours = 0\n",
    "\n",
    "scheme_diff = mapclassify.Quantiles(cbS.number_of_bikes, k=20)\n",
    "\n",
    "c_difference = percentage_for_hour_diff_plot(hours , cologne_timedGeo_orig , cologne_timedGeo_dest , c_boroughs ,scheme_diff , 'cologne')\n",
    "hours += 1\n",
    "\n",
    "scheme_diff = mapclassify.Quantiles(c_difference, k=20)\n",
    "\n",
    "while hours<24:\n",
    "    c_difference = c_difference + percentage_for_hour_diff_plot(hours , cologne_timedGeo_orig , cologne_timedGeo_dest , c_boroughs ,scheme_diff , 'cologne')\n",
    "    hours+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the 24 hour mean-values over the year for essen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells are doing the exact same computings for the city of Essen as the above cells did for Cologne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rented_bikes_in_boroughs_Start = match_Points_to_boroughs('essen', essen_timedGeo_orig)\n",
    "rbibs = rented_bikes_in_boroughs_Start\n",
    "e_validity_S = rbibs.groupby('name').count()\n",
    "rented_bikes_in_boroughs_Dest = match_Points_to_boroughs('essen', essen_timedGeo_dest)\n",
    "rbibd = rented_bikes_in_boroughs_Dest\n",
    "e_validity_D = rbibd.groupby('name').count()\n",
    "ebS = compute_PNOB_city_date ('essen' , date , rented_bikes_in_boroughs_Start , e_boroughs)\n",
    "ebD = compute_PNOB_city_date ('essen' , date , rented_bikes_in_boroughs_Dest , e_boroughs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this value shows the number of boroughs where there was no rental activity at all. \n",
    "e_validity = e_validity_S.merge(e_validity_D, left_on='name', right_on='name')\n",
    "print(len(e_boroughs) - len (e_validity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_of_map = ebS.number_of_bikes\n",
    "plot = geoplot.choropleth(\n",
    "    ebS, hue=plot_of_map, scheme=scheme_oneHour,\n",
    "    cmap='Reds', figsize=(50, 60) , legend = True\n",
    ")\n",
    "plot = plot.set_title('Distribution of tripstarts at ' + str(date)+ \"(Essen)\")\n",
    "for i in range(0,len(ebS)):\n",
    "    ebS.loc[i,'centroid_lon'] = ebS.geometry.centroid.x.iloc[i]\n",
    "    ebS.loc[i,'centroid_lat'] = ebS.geometry.centroid.y.iloc[i]\n",
    "    plt.text(ebS.loc[i,'centroid_lon'],ebS.loc[i,'centroid_lat'],ebS.loc[i,'name']\n",
    "             , horizontalalignment='center', verticalalignment ='center' ,bbox=dict(facecolor='white', alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_of_map = ebD.number_of_bikes\n",
    "plot = geoplot.choropleth(\n",
    "    ebD, hue=plot_of_map, scheme=scheme_oneHour,\n",
    "    cmap='Reds', figsize=(50, 60) , legend = True\n",
    ")\n",
    "plot = plot.set_title('Distribution of tripdestinations at ' + str(date) + \"(Essen)\")\n",
    "for i in range(0,len(ebD)):\n",
    "    ebD.loc[i,'centroid_lon'] = ebD.geometry.centroid.x.iloc[i]\n",
    "    ebD.loc[i,'centroid_lat'] = ebD.geometry.centroid.y.iloc[i]\n",
    "    plt.text(ebD.loc[i,'centroid_lon'],ebD.loc[i,'centroid_lat'],ebD.loc[i,'name']\n",
    "             , horizontalalignment='center', verticalalignment ='center' ,bbox=dict(facecolor='white', alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essen_timedGeo_orig = gpd.sjoin(essen_timedGeo_orig, e_boroughs, how=\"inner\", op='intersects')\n",
    "essen_timedGeo_orig = essen_timedGeo_orig.groupby(['hour' , 'index'])['index_right'].count()\n",
    "essen_timedGeo_orig = essen_timedGeo_orig.reset_index()\n",
    "essen_timedGeo_dest = gpd.sjoin(essen_timedGeo_dest, e_boroughs, how=\"inner\", op='intersects')\n",
    "essen_timedGeo_dest = essen_timedGeo_dest.groupby(['hour' , 'index'])['index_right'].count()\n",
    "essen_timedGeo_dest = essen_timedGeo_dest.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = 0\n",
    "\n",
    "e_difference = percentage_for_hour_diff_plot(hours , essen_timedGeo_orig , essen_timedGeo_dest , e_boroughs ,scheme_diff , 'essen')\n",
    "hours += 1\n",
    "\n",
    "\n",
    "while hours<24:\n",
    "    e_difference = e_difference + percentage_for_hour_diff_plot(hours , essen_timedGeo_orig , essen_timedGeo_dest , e_boroughs ,scheme_diff , 'essen')\n",
    "    hours+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the difference between starting and end boroughs computed for the mean day in Cologne compared to Essen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram charts show the distribution of how big the difference was for each borough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(c_difference, bins=50, edgecolor='k')\n",
    "plt.title('Cologne')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(e_difference, bins=50, edgecolor='k')\n",
    "plt.title('Essen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these standard deviations are the values, that can be compared across cities.\n",
    "c_standard_deviation = np.std(c_difference)\n",
    "print(c_standard_deviation)\n",
    "e_standard_deviation = np.std(e_difference)\n",
    "print(e_standard_deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
